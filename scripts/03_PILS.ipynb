{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_read(path):\n",
    "    '''\n",
    "    Reads .ict files to a Pandas DataFrame\n",
    "    :param path: path to the .ict data\n",
    "    :return: Pandas DataFrame with .ict data\n",
    "    '''\n",
    "    with open(path) as f:\n",
    "        # find the value in the file which tells you how many lines to skip to get to the table\n",
    "        first_line = f.readline()\n",
    "        header_line = int(first_line[0:-2].split(\",\")[0])-1\n",
    "    data = pd.read_csv(path, sep=',', skiprows=header_line)\n",
    "\n",
    "    # finds the location in the path containing the date\n",
    "    acc = 0\n",
    "    boo = False\n",
    "    for letter in path:\n",
    "        if letter == '2':\n",
    "            boo = True\n",
    "        elif boo and letter == '0':\n",
    "            acc -= 1\n",
    "            break\n",
    "        acc += 1\n",
    "        \n",
    "    # creates datetime object with the date the data was collected\n",
    "    dt = datetime(int(path[acc:acc+4]), int(path[acc+4:acc+6]), int(path[acc+6:acc+8])) \n",
    "    \n",
    "    for column in data.keys():\n",
    "        if 'Time' in column:\n",
    "            # converts seconds after midnight columns to datetime\n",
    "            data[column] = dt + pd.to_timedelta(data[column], unit='seconds')\n",
    "    data.columns = data.columns.str.replace(' ', '')\n",
    "    return data.replace(-8888, np.nan) # Converts -9999 values to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pils_paths = sorted(glob.glob('../data/*PILS*'))\n",
    "master_pils = []\n",
    "for i in range(0, len(pils_paths)):\n",
    "    master_pils.append(simple_read(pils_paths[i]))\n",
    "master_pils = pd.concat(master_pils).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv('../tables/merged_final_non_org_fixed.csv', parse_dates=['Time_Mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4665/4665 [00:01<00:00, 2433.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_row(i):\n",
    "    # finds the mean/median/max using the SMPS start and end times (because that has the lowest time resolution)\n",
    "    row = master_pils.iloc[i]\n",
    "    t_start = row['Time_Start']\n",
    "    t_stop = row['Time_Stop']\n",
    "    m_row = m[(m['Time_Mid'] >= t_start) & (m['Time_Mid'] <= t_stop)].median(numeric_only=True)\n",
    "    return m_row\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(process_row)(i) for i in tqdm(range(0, len(master_pils))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(list(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.merge(m, master_pils[['Time_Mid', 'Sodium', 'Potassium',\n",
    "       'Magnesium', 'Calcium', 'Chloride', 'Nitrate', 'Sulfate', 'Oxalate',\n",
    "       'Ammonium']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_flights = [pd.Timestamp('2022-03-22').date(), pd.Timestamp('2022-05-18').date(), pd.Timestamp('2022-05-21').date(), pd.Timestamp('2022-05-31').date(), pd.Timestamp('2022-06-18').date()]\n",
    "df_winter = d[d['Time_Mid'].dt.month.isin([11, 12, 1, 2, 3, 4]) & (~d['Time_Mid'].dt.date.isin(transit_flights))]\n",
    "df_spring = d[d['Time_Mid'].dt.month.isin([5, 6]) & (np.logical_not((d['Time_Mid'].dt.month.isin([6])) & (d['Time_Mid'].dt.year.isin([2022])))) & (~d['Time_Mid'].dt.date.isin(transit_flights))]\n",
    "df_summer = d[d['Time_Mid'].dt.month.isin([8, 9]) & (~d['Time_Mid'].dt.date.isin(transit_flights))]\n",
    "df_bermuda = d[(d['Time_Mid'].dt.month.isin([6])) & (d['Time_Mid'].dt.year.isin([2022])) & (~d['Time_Mid'].dt.date.isin(transit_flights))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_seg = [df_winter, df_spring, df_summer, df_bermuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3       2.641\n",
       "4       2.685\n",
       "        ...  \n",
       "3585      NaN\n",
       "3586      NaN\n",
       "3587      NaN\n",
       "3588      NaN\n",
       "3589      NaN\n",
       "Name: ams_tot, Length: 2233, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_winter['ams_tot']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
