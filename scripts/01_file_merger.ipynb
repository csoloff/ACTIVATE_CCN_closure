{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_read(path):\n",
    "    '''\n",
    "    Reads .ict files to a Pandas DataFrame\n",
    "    :param path: path to the .ict data\n",
    "    :return: Pandas DataFrame with .ict data\n",
    "    '''\n",
    "    with open(path) as f:\n",
    "        # find the value in the file which tells you how many lines to skip to get to the table\n",
    "        first_line = f.readline()\n",
    "        header_line = int(first_line[0:-2].split(\",\")[0])-1\n",
    "    data = pd.read_csv(path, sep=',', skiprows=header_line)\n",
    "\n",
    "    # finds the location in the path containing the date\n",
    "    acc = 0\n",
    "    boo = False\n",
    "    for letter in path:\n",
    "        if letter == '2':\n",
    "            boo = True\n",
    "        elif boo and letter == '0':\n",
    "            acc -= 1\n",
    "            break\n",
    "        acc += 1\n",
    "        \n",
    "    # creates datetime object with the date the data was collected\n",
    "    dt = datetime(int(path[acc:acc+4]), int(path[acc+4:acc+6]), int(path[acc+6:acc+8])) \n",
    "    \n",
    "    for column in data.keys():\n",
    "        if 'Time' in column:\n",
    "            # converts seconds after midnight columns to datetime\n",
    "            data[column] = dt + pd.to_timedelta(data[column], unit='seconds')\n",
    "    data.columns = data.columns.str.replace(' ', '')\n",
    "    return data.replace(-9999, np.nan) # Converts -9999 values to NaN\n",
    "\n",
    "\n",
    "def add_leg(data, legs):\n",
    "    '''\n",
    "    add leg to the data file\n",
    "    :param data: pandas data\n",
    "    :param legs: pandas legs data\n",
    "    :return: Pandas DataFrame with legs\n",
    "    '''\n",
    "    data=data.copy()\n",
    "    # creates leg column\n",
    "    data['leg'] = np.nan\n",
    "\n",
    "    # leg codes corresponding to each leg type\n",
    "    leg_key = {'00':'Takeoff/Landing', '01':'Transit', '02':'BCB', '03':'ACB', '04':'BCT', '05':'ACT', '06':'MinAlt', '07':'Ascent', '08':'Descent', '09':'Slant/Spiral', '10':'BBL', '11':'ABL', '12':'Remote Sensing (HSRL-2)', '13':'Other'}\n",
    "\n",
    "    data = data.astype({'leg': 'str'})\n",
    "    for i in range(0, len(legs)):\n",
    "        subset = data[(data['Time_Mid'] >= legs.iloc[i]['Time_Start']) & (data['Time_Mid'] <= legs.iloc[i]['Time_Stop'])].copy()\n",
    "        subset['leg'] = leg_key[str(legs.iloc[i]['LegIndex'])[-2:]]\n",
    "        data.loc[subset.index, 'leg'] = subset['leg']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads each file type\n",
    "# all data is saved in the data folder within the github repository\n",
    "ccn_paths = sorted(glob.glob('../data/*CCN*'))\n",
    "master_ccn = []\n",
    "for i in range(0, len(ccn_paths)):\n",
    "    master_ccn.append(simple_read(ccn_paths[i]))\n",
    "master_ccn = pd.concat(master_ccn).reset_index()\n",
    "ams_paths = sorted(glob.glob('../data/*AMS_*'))\n",
    "master_ams = []\n",
    "for i in range(0, len(ams_paths)):\n",
    "    master_ams.append(simple_read(ams_paths[i]))\n",
    "master_ams = pd.concat(master_ams).reset_index()\n",
    "las_paths = sorted(glob.glob('../data/*LAS*'))\n",
    "master_las = []\n",
    "for i in range(0, len(las_paths)):\n",
    "    master_las.append(simple_read(las_paths[i]))\n",
    "master_las = pd.concat(master_las).reset_index()\n",
    "smps_paths = sorted(glob.glob('../data/*SMPS*'))\n",
    "master_smps = []\n",
    "for i in range(0, len(smps_paths)):\n",
    "    master_smps.append(simple_read(smps_paths[i]))\n",
    "master_smps = pd.concat(master_smps).reset_index()\n",
    "sum_paths = sorted(glob.glob('../data/*SUMMARY*'))\n",
    "master_sum = []\n",
    "for i in range(0, len(sum_paths)):\n",
    "    master_sum.append(simple_read(sum_paths[i]))\n",
    "master_sum = pd.concat(master_sum).reset_index().rename(columns={'Time_mid':'Time_Mid'})\n",
    "leg_paths = sorted(glob.glob('../data/*LegFlags*'))\n",
    "master_leg = []\n",
    "for i in range(0, len(leg_paths)):\n",
    "    master_leg.append(simple_read(leg_paths[i]))\n",
    "master_leg = pd.concat(master_leg).reset_index()\n",
    "master_smps = add_leg(master_smps, master_leg)\n",
    "fcdp_paths = sorted(glob.glob('../data/*FCDP*'))\n",
    "master_fcdp = []\n",
    "for i in range(0, len(fcdp_paths)):\n",
    "    master_fcdp.append(simple_read(fcdp_paths[i]))\n",
    "master_fcdp = pd.concat(master_fcdp).reset_index()\n",
    "master_fcdp = master_fcdp[['Time_Start', 'LWC_FCDP']]\n",
    "v_paths = sorted(glob.glob('../data/*2DS-V*'))\n",
    "master_v = []\n",
    "for i in range(0, len(v_paths)):\n",
    "    master_v.append(simple_read(v_paths[i]))\n",
    "master_v = pd.concat(master_v).reset_index()\n",
    "master_2ds = master_v[['Time_Start', 'ED-liquid_2DS', 'Ice_Flag_2DS']]\n",
    "co_paths = sorted(glob.glob('../data/*CO_*'))\n",
    "master_co = []\n",
    "for i in range(0, len(co_paths)):\n",
    "    master_co.append(simple_read(co_paths[i]))\n",
    "master_co = pd.concat(master_co).reset_index()\n",
    "master_co = master_co[['Time_Start', 'Time_Stop', 'CO_ppm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34025/34025 [18:13<00:00, 31.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_row(i):\n",
    "    # finds the mean/median/max using the SMPS start and end times (because that has the lowest time resolution)\n",
    "    row = master_smps.iloc[i]\n",
    "    t_start = row['Time_Start']\n",
    "    t_stop = row['Time_Stop']\n",
    "    ccn_row = master_ccn[(master_ccn['Time_mid'] >= t_start) & (master_ccn['Time_mid'] <= t_stop)].median(numeric_only=True)\n",
    "    las_row = master_las[(master_las['Time_Start'] >= t_start) & (master_las['Time_Start'] <= t_stop)].median(numeric_only=True)\n",
    "    ams_row = master_ams[(master_ams['Time_Start'] >= t_start-timedelta(seconds=5)) & (master_ams['Time_Stop'] <= t_stop+timedelta(seconds=5))].mean(numeric_only=True)\n",
    "    sum_row = master_sum[(master_sum['Time_Mid'] >= t_start) & (master_sum['Time_Mid'] <= t_stop)].median(numeric_only=True)\n",
    "    fcdp_row = master_fcdp[(master_fcdp['Time_Start'] >= t_start) & (master_fcdp['Time_Start'] <= t_stop)].max(numeric_only=True)\n",
    "    v_row = master_2ds[(master_2ds['Time_Start'] >= t_start) & (master_2ds['Time_Start'] <= t_stop)].max(numeric_only=True)\n",
    "    co_row = master_co[(master_co['Time_Start'] >= t_start) & (master_co['Time_Stop'] <= t_stop)].median(numeric_only=True)\n",
    "    return ccn_row, las_row, ams_row, sum_row, fcdp_row, v_row, co_row\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(process_row)(i) for i in tqdm(range(0, len(master_smps))))\n",
    "\n",
    "ccn_mean, las_mean, ams_mean, sum_mean, fcdp_mean, v_mean, co_mean = zip(*results)\n",
    "ccn_mean = pd.DataFrame(list(ccn_mean))\n",
    "las_mean = pd.DataFrame(list(las_mean))\n",
    "ams_mean = pd.DataFrame(list(ams_mean))\n",
    "sum_mean = pd.DataFrame(list(sum_mean))\n",
    "fcdp_mean = pd.DataFrame(list(fcdp_mean))\n",
    "v_mean = pd.DataFrame(list(v_mean))\n",
    "co_mean = pd.DataFrame(list(co_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging specified columns into the merged DataFrame\n",
    "merged = pd.merge(master_smps[['Time_Mid', 'SMPS_Bin02', 'SMPS_Bin03', 'SMPS_Bin04',\n",
    "       'SMPS_Bin05', 'SMPS_Bin06', 'SMPS_Bin07', 'SMPS_Bin08', 'SMPS_Bin09',\n",
    "       'SMPS_Bin10', 'SMPS_Bin11', 'SMPS_Bin12', 'SMPS_Bin13', 'SMPS_Bin14',\n",
    "       'SMPS_Bin15', 'SMPS_Bin16', 'SMPS_Bin17', 'SMPS_Bin18', 'SMPS_Bin19',\n",
    "       'SMPS_Bin20', 'SMPS_Bin21', 'SMPS_Bin22', 'SMPS_Bin23', 'SMPS_Bin24',\n",
    "       'SMPS_Bin25', 'SMPS_Bin26', 'SMPS_Bin27', 'SMPS_Bin28', 'SMPS_Bin29',\n",
    "       'SMPS_Bin30', 'leg']], ams_mean[['Org_Ave_IsoK_STP', 'SO4_Ave_IsoK_STP',\n",
    "       'NO3_Ave_IsoK_STP', 'NH4_Ave_IsoK_STP', 'Chl_Ave_IsoK_STP',\n",
    "       'mz42_Ave_IsoK_STP', 'mz43_Ave_IsoK_STP', 'mz44_Ave_IsoK_STP',\n",
    "       'mz55_Ave_IsoK_STP', 'mz57_Ave_IsoK_STP', 'mz58_Ave_IsoK_STP',\n",
    "       'mz60_Ave_IsoK_STP', 'mz79_Ave_IsoK_STP', 'mz91_Ave_IsoK_STP']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, ccn_mean[['CCN_SS', 'N_CCN_stdPT']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, las_mean[['LAS_Bin01', 'LAS_Bin02', 'LAS_Bin03', 'LAS_Bin04', 'LAS_Bin05',\n",
    "       'LAS_Bin06', 'LAS_Bin07', 'LAS_Bin08', 'LAS_Bin09', 'LAS_Bin10',\n",
    "       'LAS_Bin11', 'LAS_Bin12', 'LAS_Bin13', 'LAS_Bin14', 'LAS_Bin15',\n",
    "       'LAS_Bin16', 'LAS_Bin17', 'LAS_Bin18', 'LAS_Bin19', 'LAS_Bin20',\n",
    "       'LAS_Bin21', 'LAS_Bin22', 'LAS_Bin23', 'LAS_Bin24', 'LAS_Bin25',\n",
    "       'LAS_Bin26']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, sum_mean[['Latitude', 'Longitude', 'GPS_altitude',\n",
    "       'Pressure_Altitude', 'Pitch', 'Roll', 'True_Heading', 'True_Air_Speed',\n",
    "       'Static_Air_Temp', 'IR_Surf_Temp', 'Static_Pressure', 'Wind_Speed',\n",
    "       'Wind_Direction']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, fcdp_mean[['LWC_FCDP']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, v_mean[['ED-liquid_2DS', 'Ice_Flag_2DS']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, co_mean[['CO_ppm']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into a table\n",
    "merged.to_csv('../tables/merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
