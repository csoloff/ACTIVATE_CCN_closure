{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_read(path):\n",
    "    '''\n",
    "    Reads .ict files to a Pandas DataFrame\n",
    "    :param path: path to the .ict data\n",
    "    :return: Pandas DataFrame with .ict data\n",
    "    '''\n",
    "    with open(path) as f:\n",
    "        # find the value in the file which tells you how many lines to skip to get to the table\n",
    "        first_line = f.readline()\n",
    "        header_line = int(first_line[0:-2].split(\",\")[0])-1\n",
    "    data = pd.read_csv(path, sep=',', skiprows=header_line)\n",
    "\n",
    "    # finds the location in the path containing the date\n",
    "    acc = 0\n",
    "    boo = False\n",
    "    for letter in path:\n",
    "        if letter == '2':\n",
    "            boo = True\n",
    "        elif boo and letter == '0':\n",
    "            acc -= 1\n",
    "            break\n",
    "        acc += 1\n",
    "        \n",
    "    # creates datetime object with the date the data was collected\n",
    "    dt = datetime(int(path[acc:acc+4]), int(path[acc+4:acc+6]), int(path[acc+6:acc+8])) \n",
    "    \n",
    "    for column in data.keys():\n",
    "        if 'Time' in column:\n",
    "            # converts seconds after midnight columns to datetime\n",
    "            data[column] = dt + pd.to_timedelta(data[column], unit='seconds')\n",
    "    data.columns = data.columns.str.replace(' ', '')\n",
    "    return data.replace(-9999, np.nan) # Converts -9999 values to NaN\n",
    "\n",
    "\n",
    "def add_leg(data, legs):\n",
    "    '''\n",
    "    add leg to the data file\n",
    "    :param data: pandas data\n",
    "    :param legs: pandas legs data\n",
    "    :return: Pandas DataFrame with legs\n",
    "    '''\n",
    "    data=data.copy()\n",
    "    # creates leg column\n",
    "    data['leg'] = np.nan\n",
    "\n",
    "    # leg codes corresponding to each leg type\n",
    "    leg_key = {'00':'Takeoff/Landing', '01':'Transit', '02':'BCB', '03':'ACB', '04':'BCT', '05':'ACT', '06':'MinAlt', '07':'Ascent', '08':'Descent', '09':'Slant/Spiral', '10':'BBL', '11':'ABL', '12':'Remote Sensing (HSRL-2)', '13':'Other'}\n",
    "\n",
    "    data = data.astype({'leg': 'str'})\n",
    "    for i in range(0, len(legs)):\n",
    "        subset = data[(data['Time_Mid'] >= legs.iloc[i]['Time_Start']) & (data['Time_Mid'] <= legs.iloc[i]['Time_Stop'])].copy()\n",
    "        subset['leg'] = leg_key[str(legs.iloc[i]['LegIndex'])[-2:]]\n",
    "        data.loc[subset.index, 'leg'] = subset['leg']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m master_v \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(v_paths)):\n\u001b[0;32m---> 43\u001b[0m     master_v\u001b[38;5;241m.\u001b[39mappend(\u001b[43msimple_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m master_v \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(master_v)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     45\u001b[0m master_2ds \u001b[38;5;241m=\u001b[39m master_v[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Start\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mED-liquid_2DS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIce_Flag_2DS\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36msimple_read\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      9\u001b[0m     first_line \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m     10\u001b[0m     header_line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(first_line[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# finds the location in the path containing the date\u001b[39;00m\n\u001b[1;32m     14\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/git/ACTIVATE_CCN_closure/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/ACTIVATE_CCN_closure/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/ACTIVATE_CCN_closure/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/git/ACTIVATE_CCN_closure/.venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:334\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reads each file type\n",
    "# all data is saved in the data folder within the github repository\n",
    "ccn_paths = sorted(glob.glob('../data/*CCN*'))\n",
    "master_ccn = []\n",
    "for i in range(0, len(ccn_paths)):\n",
    "    master_ccn.append(simple_read(ccn_paths[i]))\n",
    "master_ccn = pd.concat(master_ccn).reset_index()\n",
    "ams_paths = sorted(glob.glob('../data/*AMS_*'))\n",
    "master_ams = []\n",
    "for i in range(0, len(ams_paths)):\n",
    "    master_ams.append(simple_read(ams_paths[i]))\n",
    "master_ams = pd.concat(master_ams).reset_index()\n",
    "las_paths = sorted(glob.glob('../data/*LAS*'))\n",
    "master_las = []\n",
    "for i in range(0, len(las_paths)):\n",
    "    master_las.append(simple_read(las_paths[i]))\n",
    "master_las = pd.concat(master_las).reset_index()\n",
    "smps_paths = sorted(glob.glob('../data/*SMPS*'))\n",
    "master_smps = []\n",
    "for i in range(0, len(smps_paths)):\n",
    "    master_smps.append(simple_read(smps_paths[i]))\n",
    "master_smps = pd.concat(master_smps).reset_index()\n",
    "sum_paths = sorted(glob.glob('../data/*SUMMARY*'))\n",
    "master_sum = []\n",
    "for i in range(0, len(sum_paths)):\n",
    "    master_sum.append(simple_read(sum_paths[i]))\n",
    "master_sum = pd.concat(master_sum).reset_index().rename(columns={'Time_mid':'Time_Mid'})\n",
    "leg_paths = sorted(glob.glob('../data/*Leg*'))\n",
    "master_leg = []\n",
    "for i in range(0, len(leg_paths)):\n",
    "    master_leg.append(simple_read(leg_paths[i]))\n",
    "master_leg = pd.concat(master_leg).reset_index()\n",
    "master_smps = add_leg(master_smps, master_leg)\n",
    "fcdp_paths = sorted(glob.glob('../data/*FCDP*'))\n",
    "master_fcdp = []\n",
    "for i in range(0, len(fcdp_paths)):\n",
    "    master_fcdp.append(simple_read(fcdp_paths[i]))\n",
    "master_fcdp = pd.concat(master_fcdp).reset_index()\n",
    "master_fcdp = master_fcdp[['Time_Start', 'LWC_FCDP']]\n",
    "v_paths = sorted(glob.glob('../data/*2DS-V*'))\n",
    "master_v = []\n",
    "for i in range(0, len(v_paths)):\n",
    "    master_v.append(simple_read(v_paths[i]))\n",
    "master_v = pd.concat(master_v).reset_index()\n",
    "master_2ds = master_v[['Time_Start', 'ED-liquid_2DS', 'Ice_Flag_2DS']]\n",
    "co_paths = sorted(glob.glob('../data/*CO_*'))\n",
    "master_co = []\n",
    "for i in range(0, len(co_paths)):\n",
    "    master_co.append(simple_read(co_paths[i]))\n",
    "master_co = pd.concat(master_co).reset_index()\n",
    "master_co = master_co[['Time_Start', 'ED-Time_Stop', 'CO_ppm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(i):\n",
    "    # finds the mean/median/max using the SMPS start and end times (because that has the lowest time resolution)\n",
    "    row = master_smps.iloc[i]\n",
    "    t_start = row['Time_Start']\n",
    "    t_stop = row['Time_Stop']\n",
    "    ccn_row = master_ccn[(master_ccn['Time_mid'] >= t_start) & (master_ccn['Time_mid'] <= t_stop)].median(numeric_only=True)\n",
    "    las_row = master_las[(master_las['Time_Start'] >= t_start) & (master_las['Time_Start'] <= t_stop)].median(numeric_only=True)\n",
    "    ams_row = master_ams[(master_ams['Time_Start'] >= t_start-timedelta(seconds=5)) & (master_ams['Time_Stop'] <= t_stop+timedelta(seconds=5))].mean(numeric_only=True)\n",
    "    sum_row = master_sum[(master_sum['Time_Mid'] >= t_start) & (master_sum['Time_Mid'] <= t_stop)].median(numeric_only=True)\n",
    "    fcdp_row = master_fcdp[(master_fcdp['Time_Start'] >= t_start) & (master_fcdp['Time_Start'] <= t_stop)].max(numeric_only=True)\n",
    "    v_row = master_2ds[(master_2ds['Time_Start'] >= t_start) & (master_2ds['Time_Start'] <= t_stop)].max(numeric_only=True)\n",
    "    co_row = master_co[(master_co['Time_Start'] >= t_start) & (master_co['Time_Stop'] <= t_stop)].median(numeric_only=True)\n",
    "    return ccn_row, las_row, ams_row, sum_row, fcdp_row, v_row, co_row\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(process_row)(i) for i in tqdm(range(0, len(master_smps))))\n",
    "\n",
    "ccn_mean, las_mean, ams_mean, sum_mean, fcdp_mean, v_mean, co_mean = zip(*results)\n",
    "ccn_mean = pd.DataFrame(list(ccn_mean))\n",
    "las_mean = pd.DataFrame(list(las_mean))\n",
    "ams_mean = pd.DataFrame(list(ams_mean))\n",
    "sum_mean = pd.DataFrame(list(sum_mean))\n",
    "fcdp_mean = pd.DataFrame(list(fcdp_mean))\n",
    "v_mean = pd.DataFrame(list(v_mean))\n",
    "co_mean = pd.DataFrame(list(co_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging specified columns into the merged DataFrame\n",
    "merged = pd.merge(master_smps[['Time_Mid', 'SMPS_Bin02', 'SMPS_Bin03', 'SMPS_Bin04',\n",
    "       'SMPS_Bin05', 'SMPS_Bin06', 'SMPS_Bin07', 'SMPS_Bin08', 'SMPS_Bin09',\n",
    "       'SMPS_Bin10', 'SMPS_Bin11', 'SMPS_Bin12', 'SMPS_Bin13', 'SMPS_Bin14',\n",
    "       'SMPS_Bin15', 'SMPS_Bin16', 'SMPS_Bin17', 'SMPS_Bin18', 'SMPS_Bin19',\n",
    "       'SMPS_Bin20', 'SMPS_Bin21', 'SMPS_Bin22', 'SMPS_Bin23', 'SMPS_Bin24',\n",
    "       'SMPS_Bin25', 'SMPS_Bin26', 'SMPS_Bin27', 'SMPS_Bin28', 'SMPS_Bin29',\n",
    "       'SMPS_Bin30', 'leg']], ams_mean[['Org_Ave_IsoK_STP', 'SO4_Ave_IsoK_STP',\n",
    "       'NO3_Ave_IsoK_STP', 'NH4_Ave_IsoK_STP', 'Chl_Ave_IsoK_STP',\n",
    "       'mz42_Ave_IsoK_STP', 'mz43_Ave_IsoK_STP', 'mz44_Ave_IsoK_STP',\n",
    "       'mz55_Ave_IsoK_STP', 'mz57_Ave_IsoK_STP', 'mz58_Ave_IsoK_STP',\n",
    "       'mz60_Ave_IsoK_STP', 'mz79_Ave_IsoK_STP', 'mz91_Ave_IsoK_STP']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, ccn_mean[['CCN_SS', 'N_CCN_stdPT']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, las_mean[['LAS_Bin01', 'LAS_Bin02', 'LAS_Bin03', 'LAS_Bin04', 'LAS_Bin05',\n",
    "       'LAS_Bin06', 'LAS_Bin07', 'LAS_Bin08', 'LAS_Bin09', 'LAS_Bin10',\n",
    "       'LAS_Bin11', 'LAS_Bin12', 'LAS_Bin13', 'LAS_Bin14', 'LAS_Bin15',\n",
    "       'LAS_Bin16', 'LAS_Bin17', 'LAS_Bin18', 'LAS_Bin19', 'LAS_Bin20',\n",
    "       'LAS_Bin21', 'LAS_Bin22', 'LAS_Bin23', 'LAS_Bin24', 'LAS_Bin25',\n",
    "       'LAS_Bin26']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, sum_mean[['Latitude', 'Longitude', 'GPS_altitude',\n",
    "       'Pressure_Altitude', 'Pitch', 'Roll', 'True_Heading', 'True_Air_Speed',\n",
    "       'Static_Air_Temp', 'IR_Surf_Temp', 'Static_Pressure', 'Wind_Speed',\n",
    "       'Wind_Direction']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, fcdp_mean[['LWC_FCDP']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, v_mean[['ED-liquid_2DS', 'Ice_Flag_2DS']], left_index=True, right_index=True)\n",
    "merged = pd.merge(merged, co_mean[['CO_ppm']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into a table\n",
    "merged.to_csv('../tables/merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
